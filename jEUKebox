configfile: "config.yaml"

import io
import os
from os import listdir
from os.path import isfile, join
import sys
import pandas as pd
import numpy as np
import pathlib
import random
from Bio import SeqIO
from snakemake.exceptions import print_exception, WorkflowError  

# Major steps in workflow:
# 1. compute fastANI similarity between transcriptomes provided to pipeline
# 2. use this to determine which organisms will be in which community

# Community 1: use specification in config for what top organism should be (entry in list), else choose randomly
# Community 2: use 2 top fastANI similarity
# Community 3: use 4 top fastANI similarity
# Community 4: use any that have less than 80% ANI similarity
# Community 5: use 2 pairs with high fastANI similarity
# Community 6: use all organisms given

# 3. OrthoFinder process. Run OrthoFinder on each of the constructed communities in order to determine groups of genes with shared evolutionary history. In particular for Community 6, we want this reported on a protein basis, and to select the contigs corresponding to those proteins, so that we can see if distinct contigs are returned from the assembly process.

# Output Structure
# - base outdir
# |- fastANI
# |- OrthoFinder
# |- communities_assemblies
#  |-- community1
#  |-- community2
#  |-- community3
#  |-- community4
#  |-- community5
#  |-- community6

transcriptomes = list(config["transcriptome_selections"])
protein_files = list(config["protein_files"])
mmetsp_ids = [curr.split("/")[-1] for curr in transcriptomes]
mmetsp_ids_prot = [curr.split("/")[-1] for curr in protein_files]
communities = list(config["community_configs"])

rule all:
    input:
        fastani_output = os.path.join(config["outputdir"], "fastani", "fastani_comparison.tsv"),
        orthofinder_output = expand(os.path.join(config["outputdir"], "orthofinder",
                                                 "orthofinder_{comm}",
                                                 "orthofinder_done.txt"), comm = communities),
        assembly_output = expand(os.path.join(config["outputdir"], "mock_assemblies",
                                                 "mock_assembly_{comm}",
                                                 "mock_assembly_{comm}.fasta"), comm = communities)
 
rule placeholder:
    output:
        "placeholder.txt"
    conda:
        os.path.join("envs","workflow-env.yaml")
    shell:
        '''
        touch {output}
        '''
        
rule gen_transcriptome_names:
    input:
        transcriptomes = transcriptomes
    output:
        queries_file = os.path.join(config["outputdir"], "fastani_setup", "fastani_queries.txt"),
        references_file = os.path.join(config["outputdir"], "fastani_setup", "fastani_references.txt")
    params:
        transcriptomes = "\n".join(transcriptomes)
    shell:
        '''
        for transcriptome in {input.transcriptomes}; do
            echo -e $transcriptome >> {output.queries_file}
            echo -e $transcriptome >> {output.references_file}
        done
        '''
        
rule fastani:
    input:
        queries_file = os.path.join(config["outputdir"], "fastani_setup", "fastani_queries.txt"),
        references_file = os.path.join(config["outputdir"], "fastani_setup", "fastani_references.txt")
    output:
        tsv_file = os.path.join(config["outputdir"], "fastani", "fastani_comparison.tsv")
    params:
        transcriptomes = " ".join(transcriptomes)
    conda:
        os.path.join("envs","workflow-env.yaml")
    shell:
        '''
        fastANI --ql {input.queries_file} --rl {input.references_file} -o {output.tsv_file}
        '''

rule create_communities:
    input:
        tsv_file = os.path.join(config["outputdir"], "fastani", "fastani_comparison.tsv")
    output:
        communities_file = os.path.join(config["outputdir"], "communities.csv")
    params:
        transcriptomes = transcriptomes
    run:
        ani_file = pd.read_csv(input.tsv_file,sep="\t",header=None,names=["file1","file2","ani","XX","XXX"])
        ani_file = ani_file[ani_file.file1 != ani_file.file2]
        unrelated = list(set(params.transcriptomes) - set(ani_file.file1) - set(ani_file.file2))
        sorted_by_ani = ani_file.sort_values(by = "ani")
        communities = pd.DataFrame({"Communities": [1,2,3,4,5,6],
                                    "NumberOrganisms": [4,5,8,10,7,12],
                                    "ProportionCommunity": [[0.70,0.10,0.10,0.10],
                                                            [0.40,0.35,0.10,0.10,0.05],
                                                            [0.20,0.15,0.15,0.20,0.10,0.10,0.05,0.05],
                                                            [0.10] * 10,
                                                            [0.2,0.25,0.15,0.2,0.1,0.05,0.05],
                                                            [0.03,0.05,0.05,0.08,0.12,0.07,
                                                             0.13,0.05,0.10,0.08,0.12,0.12]],
                                    "NumberHighSimilarity": [0,2,4,0,4,4]})
        output_file = pd.DataFrame(columns = ["Community", "Organism", "Proportion"])
        for community_ind in range(len(communities.index)):
            number_orgs = int(list(communities.NumberOrganisms)[community_ind])
            number_highsim = list(communities.NumberHighSimilarity)[community_ind]
            community_curr = list(communities.Communities)[community_ind]
            organisms = []
            proportions = []
            # in community 6 we truly take anything.
            if community_curr != 6:
                number_orgs = number_orgs - number_highsim
            else:
                unrelated = list(set(params.transcriptomes))
            if number_highsim == 2:
                organisms.extend(list(ani_file.loc[:,["file1","file2"]].iloc[0]))
                # number_highsim-=2
                # number_orgs-=2
            elif (number_highsim == 4) & (community_curr == 3):
                # this is the community where we want all 4 to be related to _each other_
                top_related = []
                ani_rows = 0
                while (ani_rows < len(ani_file.index)) & (len(top_related) < 4):
                    candidate_1 = list(ani_file.file1)[ani_rows]
                    candidate_2 = list(ani_file.file2)[ani_rows]
                    if (len(top_related) == 0) | (candidate_1 in top_related) | (candidate_2 in top_related):
                        top_related.extend([candidate_1,candidate_2])
                        top_related = list(set(top_related))
                    ani_rows+=1
                        
                 
                organisms.extend(top_related)
            elif (number_highsim == 4) & (community_curr == 5):
                # this is the community where we want all 4 to be related, but not to each other
                top_related = []
                ani_rows = 0
                while (ani_rows < len(ani_file.index)) & (len(top_related) < 4):
                    candidate_1 = list(ani_file.file1)[ani_rows]
                    candidate_2 = list(ani_file.file2)[ani_rows]
                    if (len(top_related) == 0) | ((candidate_1 not in top_related) & (candidate_2 not in top_related)):
                        top_related.extend([candidate_1,candidate_2])
                        top_related = list(set(top_related))
                        
                    ani_rows+=1
                        
                organisms.extend(top_related)
                
            if number_orgs <= len(unrelated):
                organisms.extend(np.random.choice(unrelated, number_orgs, replace=False))
            else:
                organisms.extend(np.random.choice(unrelated, number_orgs, replace=True))
            
            proportions.extend(list(communities.ProportionCommunity[community_ind]))
            mmetsp_inds = [curr.split("/")[-1] for curr in organisms]
            output_file = output_file.append(pd.DataFrame({"Community": community_curr,
                                             "Organism": organisms,
                                             "MMETSP_inds": mmetsp_inds,
                                             "Proportion": proportions}))
            
        output_file.to_csv(output.communities_file)


rule organize_folders:
    input:
        communities_file = os.path.join(config["outputdir"], "communities.csv")
    output:
        community_files_prot = os.path.join(config["outputdir"], "community_{comm}_prot", "{comm}_complete.csv"),
        community_files = os.path.join(config["outputdir"], "community_{comm}", "{comm}_complete.csv")
    params:
        community = "{comm}",
        directory_prot = os.path.join(config["outputdir"], "community_{comm}_prot"),
        directory_nucl = os.path.join(config["outputdir"], "community_{comm}")
    run:
        community_spec = pd.read_csv(input.communities_file)
        community_spec = community_spec[community_spec.Community == int(params.community)]
        os.system("mkdir -p " + str(params.directory_prot)) 
        os.system("mkdir -p " + str(params.directory_nucl))
        for com_ind in range(len(community_spec.index)):
            protein_file = protein_files[np.where([(curr == str(list(community_spec.Organism)[com_ind])) for curr in transcriptomes])[0][0]]
            nucl_file = list(community_spec.Organism)[com_ind]
            protein_ind = nucl_file.split("/")[-1].split(".")[0]
            os.system("cp " + str(protein_file) + " " + os.path.join(params.directory_prot, str(protein_ind) + ".pep.fa"))
            os.system("cp " + str(nucl_file) + " " + os.path.join(params.directory_nucl, str(protein_ind) + ".fasta"))
            
        if len(community_spec.index) > 0:
            os.system("touch " + str(output.community_files_prot))
            os.system("touch " + str(output.community_files))
    
rule orthofinder:
    input:
        community_files_prot = os.path.join(config["outputdir"], "community_{comm}_prot", "{comm}_complete.csv"),
        community_files = os.path.join(config["outputdir"], "community_{comm}", "{comm}_complete.csv")
    output:
        outputfile = os.path.join(config["outputdir"], "orthofinder",
                                                 "orthofinder_{comm}",
                                                 "orthofinder_done.txt"),
        orthfinder_genct = os.path.join(config["outputdir"],"orthofinder","orthofinder_{comm}",
                                        "Results_Jul17","Orthogroups","Orthogroups.GeneCount.tsv"),
        orthfinder_OGs = os.path.join(config["outputdir"],"orthofinder","orthofinder_{comm}",
                                        "Results_Jul17","Orthogroups","Orthogroups.tsv")
    params:
        outfold = os.path.join(config["outputdir"],"orthofinder","orthofinder_{comm}"),
        outfolder = config["outputdir"],
        folder = os.path.join(config["outputdir"],"community_{comm}_prot")
    conda:
        os.path.join("envs","workflow-env.yaml")
    shell:
        '''
        rm -rf {params.outfold}
        orthofinder -t 108 -o {params.outfold} -f {params.folder}
        touch {output.outputfile}
        '''

rule create_assemblies:
    input:
        community_files_prot = os.path.join(config["outputdir"], "community_{comm}_prot", "{comm}_complete.csv"),
        community_files = os.path.join(config["outputdir"], "community_{comm}", "{comm}_complete.csv"),
        communities_file = os.path.join(config["outputdir"], "communities.csv"),
        orthfinder_genct = os.path.join(config["outputdir"],"orthofinder","orthofinder_{comm}",
                                        "Results_Jul17","Orthogroups","Orthogroups.GeneCount.tsv"),
        orthfinder_OGs = os.path.join(config["outputdir"],"orthofinder","orthofinder_{comm}",
                                        "Results_Jul17","Orthogroups","Orthogroups.tsv")
    output:
        mock_assembly = os.path.join(config["outputdir"], "mock_assemblies",
                                                 "mock_assembly_{comm}",
                                                 "mock_assembly_{comm}.fasta")
    params:
        community_dir = os.path.join(config["outputdir"], "community_{comm}")
    run:
        community_spec = pd.read_csv(input.communities_file)
        files_inassembly = os.listdir(params.community_dir)
        community_spec = community_spec[community_spec.MMETSP_inds.isin(files_inassembly)] 
                                            #community_spec.MMETSP_inds in files_inassembly,:]
                                            
        # we want to use the OrthoFinder output to ensure that each assembly contains contigs from
        # OG spanned by ALL species in assembly.
        
        gene_ct = pd.read_csv(input.orthfinder_genct,sep="\t")
        orthogroups = pd.read_csv(input.orthfinder_OGs,sep="\t")
        gene_ct = gene_ct.replace(0, np.nan)
        gene_ct = gene_ct.dropna(how='any', axis=0)
        to_write=[]
        for row_ind in range(len(community_spec.index)):
            #record_dict = SeqIO.to_dict(SeqIO.parse(list(community_spec.Organism)[row_ind], "fasta"))
            record_list = list(SeqIO.parse(list(community_spec.Organism)[row_ind], "fasta"))
            percentage = list(community_spec.Proportion)[row_ind]
            total_items = len(record_list) #len(record_dict.items())
            #random_reads = random.sample(record_dict.items(), int(total_items * percentage))
            random_num = list(np.random.randint(0, high=total_items, size=int(total_items * percentage)))
            random_num = random.choice(list(range(0,total_items)), size=int(total_items * percentage), replace=False)
            to_write.extend([record_list[random_num_curr] for random_num_curr in random_num])
        with open(output.mock_assembly, 'w') as handle:
            SeqIO.write(to_write, handle, 'fasta')
        
rule rsubreads:
    output:
        "mocksubreads.txt"
    conda:
        os.path.join("envs","R-env.yaml")
    shell:
        '''
        # run Rscript
        touch mocksubreads.txt
        '''